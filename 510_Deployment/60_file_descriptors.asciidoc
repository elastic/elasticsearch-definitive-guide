
=== File Descriptors and MMap

Lucene uses a _very_ large number of files. At the same time, Elasticsearch uses
a large number of sockets to communicate between nodes and HTTP clients. All of
this requires available file descriptors.

Sadly, many modern Linux distributions ship with a paltry 1,024 file descriptors
allowed per process. This is _far_ too low for even a small Elasticsearch node,
let alone one that is handling hundreds of indices.

You should increase your file descriptor count to something very large, such as
64,000. This process is irritatingly difficult and highly dependent on your
particular OS and distribution. Consult the documentation for your OS to
determine how best to change the allowed file descriptor count.

Once you think you've changed it, check Elasticsearch to make sure it really
does have enough file descriptors:

[source,js]
----
{
  "cluster_name": "elasticsearch",
  "nodes": {
    "nLd81iLsRcqmah-cuHAbaQ": {
      "timestamp": 1471516160318,
      "name": "Marsha Rosenberg",
      "transport_address": "127.0.0.1:9300",
      "host": "127.0.0.1",
      "ip": [
        "127.0.0.1:9300",
        "NONE"
      ],
      "process": {
        "timestamp": 1471516160318,
        "open_file_descriptors": 155,
        "max_file_descriptors": 10240, <1>
        "cpu": {
          "percent": 0,
          "total_in_millis": 25084
        },
        "mem": {
          "total_virtual_in_bytes": 5221900288
        }
      }
    }
  }
}
----
<1> The `max_file_descriptors` field shows the number of available descriptors
that the Elasticsearch process can access.

Elasticsearch also uses a mix of NioFS and MMapFS ((("MMapFS")))for the various
files. Ensure that you configure the maximum map count so that there is ample
virtual memory available for mmapped files. This can be set temporarily:

[source,js]
----
sysctl -w vm.max_map_count=262144
----

Or you can set it permanently by modifying `vm.max_map_count` setting in your
`/etc/sysctl.conf`.
