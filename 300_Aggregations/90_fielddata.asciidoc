
=== Field Data

Aggregations work via a data structure known as _field data_ (briefly introduced 
in <<fielddata-intro>>).  Field data is often the largest consumer of memory
in an Elasticsearch cluster, so it is important to understand how it works.

Field data exists because inverted indices are only efficient for certain operations.
The inverted index excels at finding documents which contain a term.  It does not
perform well in the opposite direction: determining which terms exist in a single 
document. Aggregations need this secondary access pattern.  

Consider the following inverted index:

    Term      Doc_1   Doc_2   Doc_3
    ------------------------------------
    Quick   |       |   X   |   X
    The     |   X   |       |
    brown   |   X   |   X   |  
    dog     |   X   |       |   X
    dogs    |       |   X   |   X  
    fox     |   X   |       |   X
    foxes   |       |   X   |  
    in      |       |   X   |  
    jumped  |   X   |       |   X
    lazy    |   X   |   X   |  
    leap    |       |   X   |  
    over    |   X   |   X   |   X  
    quick   |   X   |       |
    summer  |       |   X   |  
    the     |   X   |       |   X
    ------------------------------------

If we want to compile a complete list of terms in any document that mentions 
"brown", we might build a query like so:

[source,js]
----
GET /my_index/_search
{
    "query" : {
        "match" : {
            "body" : "brown"
        }
    },
    "aggs" : {
        "terms" : {
            "field" : "body"
        }
    }
}
----

The query portion is easy and efficient.  First find "brown" in the inverted index,
then scan across all the columns to see which docs contain "brown".  We can very
quickly see that `Doc_1` and `Doc_2` contain the token "brown".

Now for the aggregation portion we need to find all the unique terms in `Doc_1` 
and `Doc_2`.  With the inverted index, this is a very expensive process.  The 
only way to do so is by iterating row by row and collecting tokens from `Doc_1` 
and `Doc_2` columns.  This is slow and scales poorly: as the number of terms and 
documents grows, so does the execution time.

To address this problem, field data inverts the inverted index.  We can transform
the inverted index above into the following field data representation:

    Doc      Terms
    -----------------------------------------------------------------
    Doc_1 | The, brown, dog, fox, jumped, lazy, over, quick, the
    Doc_2 | Quick, brown, dogs, foxes, in, lazy, leap, over, summer
    Doc_3 | Quick, dog, dogs, fox, jumped, over, the
    -----------------------------------------------------------------

Once the data has been uninverted, it is trivial to collect the unique tokens from
`Doc_1` and `Doc_2`.  Go to the rows for each document, collect all the terms and
take the union of the two sets.

[NOTE]
====
You may be objecting that this would be horribly inefficient in terms of memory
usage.  And you would be right.

// I think here the introduction of per-segment ordinal map is a bit abrupt for the Lucene newbies
// It could be nice to at least add a pointer to "eagerly loading global ordinals" part
// which explains it later.
Internally, field data is more sophisticated.  Values are stored in per-segment 
ordinal maps (and global ordinals for certain types).  Field data is also compressed
using a variety of bit packing tricks: packed integers, monotonic delta compression,
etc.

Conceptually, however, the above description holds true.
====   

Thus, search and aggregations are closely intertwined.  Search finds documents
using the inverted index.  Aggregations collect and aggregate values from field
data, which is itself generated from the inverted index.

The rest of this chapter will be discussing various functionality that either
decreases field data's memory footprint, or speeds up execution speed.
