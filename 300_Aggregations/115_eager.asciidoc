
=== Pre-Loading Field Data

The default behavior of Elasticsearch is to load field data *lazily*.  The first
time Elasticsearch encounters a query which needs field data for a particular
field, it will load that entire field into memory.

For small datasets, this is a negligible amount of time.  But if you have a few
billion documents and need to load 8gb into memory, the loading time could
last a second or two (or more).  If the query was servicing a consumer-facing
site, this latency could have a real impact on your business.  Customers are 
accustomed to sub-second response times, and all of a sudden are hit by a response
of 4s.

There are three methods to combat this latency spike.  All are derivations on
the same concept: pre-load the field data so that there is no latency spike.

==== Eagerly Loading Field Data

The first tool is called *eager loading* (as opposed to the default *lazy* loading).
When enabled for a field, Elasticsearch will pre-load field data at index-time.
Immediately after a new segment has been generated, but *before* the segment is
added to the "searchable" pool, eager fields are pre-loaded into memory.

Only after eager fields have been pre-loaded will the segment become visible to
search.  This means that the fields are already resident in memory and an aggregation
using the field will never experience a hit to latency while the data structure
is being "hydrated".

Eager loading is enabled on a per field basis, so you can control which fields
are pre-loaded:

[source,js]
----
PUT /fielddata/eager/_mapping
{
    "eager" : {
        "properties" : {
            "price_usd": {
                "type": "integer",
                "fielddata": {
                    "loading" : "eager" <1>
                }
            }
        }
    }
}
----
<1> By setting `fielddata.loading: eager`, we tell Elasticsearch to pre-load
this field's contents into memory

[WARN]
====
When eager loading is enabled, it may reduce the "real time" aspect of your data.
Eager loading simply shifts the cost of loading field data.  Instead of paying
at query-time, you pay at index-time.

After a segment is created (because of new documents, or merges of existing
segments) the eager fields must be preloaded before the segment is searchable.  
If the segment is  large, or the fields are unusually large, this will add time 
before the segment is "searchable".

The trade-off for hiding query latency is reducing the realtime-ness of your index.
====

==== Eagerly loading Global Ordinals

There is an optimization for string fields which reduces their memory footprint
and increases query speed.  This optimization, called *global ordinals*, maintains
a map of string values to unique IDs.  Recall the example that as shown to describe
field data structure:

    Doc      Terms
    -----------------------------------------------------------------
    Doc_1 | The, brown, dog, fox, jumped, lazy, over, quick, the
    Doc_2 | Quick, brown, dogs, foxes, in, lazy, leap, over, summer
    Doc_3 | Quick, dog, dogs, fox, jumped, over, the
    -----------------------------------------------------------------

You may have thought this wasn't terribly efficient memory layout, and you would
be right.  For example, the term `"jumped"` appears twice, taking up 12 bytes total
(six bytes * two documents).  This inefficiency is exaggerated as more documents
share the same term.  Ordinals fix this inefficiency by replacing
string representations with an integer and using that to look up the value
in the ordinal map later.  For example, the data structure looks more like this:

    Ordinal Term 
    --------------
    1   | Quick 
    2   | The
    3   | brown 
    4   | dog 
    5   | dogs 
    6   | fox 
    7   | foxes 
    8   | in 
    9   | jumped
    10  | lazy 
    11  | leap 
    12  | over 
    13  | quick  
    14  | summer 
    15  | the 
    --------------

    Doc      Ordinals
    -----------------------------------------------------------------
    Doc_1 | 2, 3, 4, 6, 9, 10, 12, 13, 15
    Doc_2 | 1, 3, 5, 7, 8, 10, 11, 12, 14
    Doc_3 | 1, 4, 5, 6, 9, 12, 15
    -----------------------------------------------------------------

Once mapped to ordinals, the data structure can be packed much more efficiently.
Most strings are larger than integers (in bytes), and integers can be packed
using compression techniques much better.

Ordinal maps are maintained for each segment -- each segment only has a unique
mapping of terms-to-ordinals for the data within that segment.  But when an
aggregation is compiling results (say, the top 10 terms) it obtains terms from
across many segments.  Since it needs to decode the ordinal map, aggregations
perform a process which merges ordinal maps into a *global* ordinal.

This global ordinal represents the unique mapping of every term in your index
to a unique numeric ID.  By default, this happens every time you execute an 
aggregation.

It isn't a *super* slow process, but it does add execution time to your query.
Similar to field data, the global ordinal map can be pre-built and loaded into
memory.  Queries will use the pre-loaded version instead of recomputing on
each execution.  

Eagerly loading global ordinals is enabled on a per-field basis:

[source,js]
----
PUT /fielddata/eager/_mapping
{
    "eager" : {
        "properties" : {
            "price_euro": {
                "type": "integer",
                "fielddata": {
                    "loading" : "eager_global_ordinals"
                }
            }
        }
    }
}
----

Eagerly loading ordinals *also* eagerly loads the field data, since it is required
to build the ordinal map.  So be aware that when you load ordinals, you also
inherit the pros/cons of eagerly loaded field data.

[WARN]
====
The warning about eager loading field data applies to eager global ordinals too.
This setting shifts the cost of creating the ordinal map from query-time to
index-time.

There is a difference, however.  Field data is loaded once and then reused constantly.
Eager loading simply gets rid of the latency for "cold" data structures - the 
time required to load the data to memory.  Eagerly loading field data is a one-time
cost savings.

Global ordinals, however, are rebuilt on each query execution.  If your application
is search-heavy, eagerly loading the global ordinals will save you time on each
search execution.  Assuming you can pay the index-time cost of refreshing
the ordinal map, it can shave considerable time off your queries.
====

==== Warmers

Finally, we come to *warmers*.  The previous two techniques were very
special-purpose.  Warmers, in contrast, are a more general tool used to pre-load
a variety of caches in Elasticsearch.

Warmers work by registering one or more queries with Elasticsearch that you want
run after segments are created.  The purpose is identical to eagerly loading
field data: to populate cold caches before a segment becomes "searchable", so that
your user never sees a spike in latency.

Unlike eager loading, warmers can be used to also populate filter caches, parent/
child `id_cache`, etc.

Let's register a warmer, then talk about what's happening:

[source,js]
----
PUT /fielddata/_warmer/warmer_1 <1>
{
    "query" : {
        "filtered" : {
            "query" : { "match_all" : {} },
            "filter" : {
                "term" : { "category" : "elasticsearch" } <2>
            }
        }
    },
    "aggs" : {
        "price" : {
            "histogram" : {
                "field" : "price", <3>
                "interval" : 10
            }
        }
    }
}
----
<1> Warmers are associated with an index (`fielddata`) and are registered using
the `_warmer` endpoint and a unique ID (`warmer_1`)
<2> By including a `term` filter, filter caches for "elasticsearch" on the "category"
field will be pre-populated
<3> And by invoking an aggregation, the field data for "price" will be pre-loaded

Warmers are registered with a specific index.  In this example, we are adding
a warmer to the `fielddata` index.  Each warmer is given a unique ID because
you can have multiple warmers per index.

Then you just specify a query.  Any query.  It can include queries, filters,
aggregations, sort values, scripts...literally any valid query DSL.  The point is
to register queries that are representative of the traffic that your users will
generate, so that appropriate caches can be pre-populated.

When a new segment is created, Elasticsearch will *literally* execute the queries
registered in your warmers.  The act of executing these queries will force
caches to be loaded.  Only after all warmers have been executed will the segment
be made visible to search.

[WARN]
====
Similar to eager loading, warmers shift the cost of cold caches to index-time.
When registering warmers, it is important to be judicious.  You *could* add
thousands of warmers to make sure every cache is populated...but that will
drastically slow down how long it takes for new segments to be made searchable.

In practice, select a handful of queries which represent the majority of your
user's queries and register those.
====
