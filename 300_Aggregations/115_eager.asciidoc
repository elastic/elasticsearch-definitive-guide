
=== Pre-Loading Field Data

The default behavior of Elasticsearch is to load field data _lazily_.  The first
time Elasticsearch encounters a query which needs field data for a particular
field, it will load that entire field into memory.

For small datasets, this requires a negligible amount of time.  But if you have a few
billion documents and need to load 8gb into memory, the loading time could
last a second or two (or more).  If the query was servicing a consumer-facing
site, this latency could have a real impact on your business.  Customers are
accustomed to sub-second response times, and all of a sudden are hit by a response
of 4s.

There are three methods to combat this latency spike.  All are derivations on
the same concept: pre-load the field data so that there is no latency spike.

==== Eagerly Loading Field Data

The first tool is called _eager loading_ (as opposed to the default lazy loading).
When enabled for a field, Elasticsearch will pre-load field data at index-time.
Immediately after a new segment has been generated, but _before_ the segment is
added to the "searchable" pool, eager fields are pre-loaded into memory.

Only after eager fields have been pre-loaded will the segment become visible to
search.  This means that the fields are already resident in memory and a user
will never experience a "cold cache" and corresponding latency spike.

Eager loading is enabled on a per field basis, so you can control which fields
are pre-loaded:

[source,js]
----
PUT /fielddata/eager/_mapping
{
    "eager" : {
        "properties" : {
            "price_usd": {
                "type": "integer",
                "fielddata": {
                    "loading" : "eager" <1>
                }
            }
        }
    }
}
----
<1> By setting `fielddata.loading: eager`, we tell Elasticsearch to pre-load
this field's contents into memory

[WARNING]
====
When eager loading is enabled, it may reduce the "real time" aspect of your data.
Eager loading simply shifts the cost of loading field data.  Instead of paying
at query-time, you pay at index-time.

After a segment is created (because of new documents, or merges of existing
segments) the eager fields must be preloaded before the segment is searchable.
If the segment is  large, or the fields are unusually large, this will add time
before the segment is "searchable".

The trade-off for hiding query latency is reducing the realtime-ness of your index.
====

==== Eagerly loading Global Ordinals

There is an optimization for string fields which reduces their memory footprint
and increases query speed.  This optimization, called _global ordinals_, maintains
a map of string values to unique IDs.  Recall the example we used to describe
field data at the top of the chapter:

    Doc   | Terms
    -----------------------------------------------------------------
    Doc_1 | The, brown, dog, fox, jumped, lazy, over, quick, the
    Doc_2 | Quick, brown, dogs, foxes, in, lazy, leap, over, summer
    Doc_3 | Quick, dog, dogs, fox, jumped, over, the
    -----------------------------------------------------------------

You may have thought this wasn't terribly efficient memory layout, and you would
be right.  For example, the term `"jumped"` appears twice, taking up 12 bytes total
(six bytes * two documents).  This inefficiency is increased as more documents
share the same terms, and as terms get larger.  Ordinals fix this inefficiency
by replacing string representations with an integer and using that to look up the
value in the ordinal map later.  For example, the data structure looks more like
these two maps:

    Ordinal | Term
    ------------------
    1       | Quick
    2       | The
    3       | brown
    4       | dog
    5       | dogs
    6       | fox
    7       | foxes
    8       | in
    9       | jumped
    10      | lazy
    11      | leap
    12      | over
    13      | quick
    14      | summer
    15      | the
    -------------------

    Doc   | Ordinals
    -----------------------------------------------------------------
    Doc_1 | 2, 3, 4, 6, 9, 10, 12, 13, 15
    Doc_2 | 1, 3, 5, 7, 8, 10, 11, 12, 14
    Doc_3 | 1, 4, 5, 6, 9, 12, 15
    -----------------------------------------------------------------

Once mapped to ordinals, the data structure can be packed much more efficiently.
Most strings are larger than integers (in bytes), and integers can be packed
using compression techniques much better.

Ordinal maps are maintained for each segment -- each segment only has a unique
mapping of terms-to-ordinals for the data within that segment.  But when an
aggregation is compiling results (say, the top 10 terms) it obtains terms from
across many segments.  Since it needs to decode the ordinal map, aggregations
perform a process which merges individual segment-level ordinal maps into a
single _global_ ordinal.

This global ordinal represents the unique mapping of every term in your index
to a unique numeric ID.  By default, this happens every time you execute an
aggregation.

It is a fairly fast process, but it does add execution time to your query.
Similar to field data, the global ordinal map can be pre-built and loaded into
memory.  Queries will use the pre-loaded version instead of recomputing on
each execution.

Eagerly loading global ordinals is enabled on a per-field basis:

[source,js]
----
PUT /fielddata/eager/_mapping
{
    "eager" : {
        "properties" : {
            "price_euro": {
                "type": "integer",
                "fielddata": {
                    "loading" : "eager_global_ordinals"
                }
            }
        }
    }
}
----

Eagerly loading ordinals _also_ eagerly loads the field data, since it is required
to build the ordinal map.  So be aware that when you load ordinals, you also
inherit the pros/cons of eagerly loaded field data.

[WARNING]
====
The warning about eager loading field data applies to eager global ordinals too.
This setting shifts the cost of creating the ordinal map from query-time to
index-time.

There is a difference, however.  Field data is loaded once and then reused constantly.
Eager loading simply gets rid of the latency for "cold" data structures - the
time required to load the data to memory.  Eagerly loading field data is a one-time
cost savings.

Global ordinals are rebuilt on each query execution.  If your application
is search-heavy, eagerly loading the global ordinals will save you time on each
search execution.  Assuming you can pay the index-time cost of refreshing
the ordinal map, it can shave considerable time off your queries.
====

==== Warmers

Finally, we come to _warmers_.  The previous two techniques were very
special-purpose.  Warmers, in contrast, are a more general tool used to pre-load
a variety of caches in Elasticsearch.

Warmers work by registering one or more queries with Elasticsearch that you want
run after segments are created.  The purpose is identical to eagerly loading
field data: to populate cold caches before a segment becomes "searchable", so that
your user never sees a spike in latency.

Unlike eager loading, warmers can be used to also populate filter caches, parent/
child `id_cache`, etc.

Let's register a warmer, then talk about what's happening:

[source,js]
----
PUT /fielddata/_warmer/warmer_1 <1>
{
    "query" : {
        "filtered" : {
            "query" : { "match_all" : {} },
            "filter" : {
                "term" : { "category" : "elasticsearch" } <2>
            }
        }
    },
    "aggs" : {
        "price" : {
            "histogram" : {
                "field" : "price", <3>
                "interval" : 10
            }
        }
    }
}
----
<1> Warmers are associated with an index (`fielddata`) and are registered using
the `_warmer` endpoint and a unique ID (`warmer_1`)
<2> By including a `term` filter, filter caches for "elasticsearch" on the "category"
field will be pre-populated
<3> And by invoking an aggregation, the field data for "price" will be pre-loaded

Warmers are registered with a specific index.  In this example, we are adding
a warmer to the `fielddata` index.  Each warmer is given a unique ID because
you can have multiple warmers per index.

Then you just specify a query.  Any query.  It can include queries, filters,
aggregations, sort values, scripts...literally any valid query DSL.  The point is
to register queries that are representative of the traffic that your users will
generate, so that appropriate caches can be pre-populated.

When a new segment is created, Elasticsearch will _literally_ execute the queries
registered in your warmers.  The act of executing these queries will force
caches to be loaded.  Only after all warmers have been executed will the segment
be made visible to search.

[WARNING]
====
Similar to eager loading, warmers shift the cost of cold caches to index-time.
When registering warmers, it is important to be judicious.  You *could* add
thousands of warmers to make sure every cache is populated...but that will
drastically slow down how long it takes for new segments to be made searchable.

In practice, select a handful of queries which represent the majority of your
user's queries and register those.
====

There are a number of administrative details (getting existing warmers,
deleting warmers, etc) which have been omitted from this explanation.  Refer
to the {ref}indices-warmers.html#warmer-adding[warmers documentation] for the rest
of the details.




