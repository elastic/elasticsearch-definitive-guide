=== Fetch Phase
=== 반환(?) 단계

The query phase identifies which documents satisfy((("distributed search execution", "fetch phase")))((("fetch phase of distributed search"))) the search request, but we
still need to retrieve the documents themselves. This is the job of the fetch
phase, shown in <<img-distrib-fetch>>.

질의 단계는 어떤 문서가 질의 요청을 만족하는지를 찾아내는 단계이다. 하지만, 아직 문서 자체를 가져오지는 못했다. 이것이 바로 다음 <<img-distrib-fetch>>에서 설명하고 있는 가져오기 단계에서 벌어지는 일이다.

[[img-distrib-fetch]]
.Fetch phase of distributed search

image::images/elas_0902.png["Fetch Phase of distributed search"]

[[img-distrib-fetch]]
.분산 검색의 반환 단계
image::images/elas_0902.png["분산 검색의 반환 단계"]

The distributed phase consists of the following steps:

1. The coordinating node identifies which documents need to be fetched and
   issues a multi `GET` request to the relevant shards.

2. Each shard loads the documents and _enriches_ them, if required, and then
   returns the documents to the coordinating node.

3. Once all documents have been fetched, the coordinating node returns the
   results to the client.

분산 단계는 다음 세 단계로 구성된다.

1. 통합 노드는 어떤 문서들이 반환되어야 할 지를 결정하고, 연관된 샤드에 다중 `GET` 요청을 보낸다.

2. 각 샤드는 문서를 로드하고, 필요할 경우 로드한 문서를 _가공_한 다음 통합 노드로 반환한다.

3. 모든 문서들이 반환되면, 통합 노드는 클라이언트에 결과를 반환한다.

The coordinating node first decides which documents _actually_ need to be
fetched. For instance, if our query specified `{ "from": 90, "size": 10 }`,
the first 90 results would be discarded and only the next 10 results would
need to be retrieved. These documents may come from one, some, or all of the
shards involved in the original search request.

통합 노드는 먼저 어떤 문서들이 _실제로_ 반환되어야 할 지를 결정한다.
예를 들어, 질의에서 `{ "from": 90, "size": 10 }`라고 조건을 지정했다면, 처음 90개의 결과는 버려지고 다음 10개만이 반환되어야 한다.
이 문서들은 최초의 검색 요청에 연관된 샤드 중 하나 또는 다수 개의 샤드에서 반환한 것일 수도 있고, 모든 샤드에서 반환된 것일 수도 있다.

The coordinating node builds a <<distrib-multi-doc,multi-get request>> for
each shard that holds a pertinent document and sends the request to the same
shard copy that handled the query phase.

통합 노드는 관련된 문서를 가진 각 샤드에 대한 <<distrib-multi-doc,multi-get request>>를 구성하고,
질의 단계를 처리한 것과 동일한 샤드 복제본에 요청을 전송한다.

The shard loads the document bodies--the `_source` field--and, if
requested, enriches the results with metadata and
<<highlighting-intro,search snippet highlighting>>.
Once the coordinating node receives all results, it assembles them into a
single response that it returns to the client.

샤드는 문서 바디 (`_source` 필드)를 로드하고, 필요할 경우 메타데이터와 <<highlighting-intro, 검색어 하이라이트>>로 결과를 가공한다.
통합 노드는 모든 결과를 수신하면 클라이언트에 반환할 단일 응답으로 재조합한다.

.Deep Pagination
****

The query-then-fetch process supports pagination with the `from` and `size`
parameters, but _within limits_. ((("size parameter")))((("from parameter")))((("pagination", "supported by query-then-fetch process")))((("deep paging, problems with"))) Remember that each shard must build a priority
queue of length `from + size`, all of which need to be passed back to
the coordinating node. And the coordinating node needs to sort through
`number_of_shards * (from + size)` documents in order to find the correct
`size` documents.

Depending on the size of your documents, the number of shards, and the
hardware you are using, paging 10,000 to 50,000 results (1,000 to 5,000 pages)
deep should be perfectly doable. But with big-enough `from` values, the
sorting process can become very heavy indeed, using vast amounts of CPU,
memory, and bandwidth.  For this reason, we strongly advise against deep paging.

In practice, ``deep pagers'' are seldom human anyway.  A human will stop
paging after two  or three pages and will change the search criteria. The
culprits are usually bots or web spiders that tirelessly keep fetching page
after page until your servers crumble at the knees.

If you _do_ need to fetch large numbers of docs from your cluster, you can
do so efficiently by disabling sorting with the `scan` search type,
which we discuss <<scan-scroll,later in this chapter>>.

****

.깊은 페이지 매김
****

쿼리-후-반환 프로세스는 `from`과 `size` 파라미터를 이용해 페이지 매김을 지원하지만, 거기에는 _제한이 있다_. ((("size parameter")))((("from parameter")))((("pagination", "supported by query-then-fetch process")))((("deep paging, problems with")))
앞에서 설명했듯이, 각 샤드는 `from + size` 길이의 우선순위 큐를 구성하고, 이 큐 모두가 통합 노드로 반환되어야 한다.
그리고 통합 노드는 `number_of_shards * (from + size)` 만큼의 문서를 정렬하여 정확한 `size` 만큼의 문서를 찾아내야 한다.

문서의 수와 샤드의 수, 그리고 사용 중인 하드웨어에 따라 10,000개에서 50,000개의 결과 (1,000개에서 5,000 페이지)를 페이징 하는 것은 충분히 가능하다.
하지만, 충분히 큰 `from` 값이 주어지면, 정렬 프로세스로 인한 부하가 지나치게 커져 대부분의 CPU, 메모리, 대역폭을 소모하게 된다. 이런 이유로 우리는 깊은 페이지 매김을 사용하지 않을 것을 강력히 권고한다.

사실, 사람은 일반적으로 ``깊은 페이지 매김 유발자''가 되지 않는다. 사람은 2 ~ 3 페이지 정도 살펴본 후 페이지 넘김을 멈추고 검색 조건을 바꿀 것이다.
쉼없이 반복적으로 페이징을 요청하여 서버를 다운시키는 것들은 보통 봇이나 웹 스파이더(검색 엔진 크롤러)들이다.

_반드시_ 클러스터에서 대량의 문서를 가져와야만 한다면, `scan` 검색 타입을 이용해 정렬을 비활성화 하여 효율적으로 문서를 반환하도록 할 수 있다.
`scan` 검색 타입에 대해서는 <<scan-scroll, 이 장 후반부>>에서 다루도록 하겠다.
****
